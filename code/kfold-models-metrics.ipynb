{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89414db4",
   "metadata": {},
   "source": [
    "# Logistic regression, statistical methods, KNN and decision trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "492b06e7",
   "metadata": {},
   "source": [
    "### 1 - Dataset: jsvulnerability_balanced.csv. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5e222ff",
   "metadata": {},
   "source": [
    "### a) cv = 10 folds. Use the following models:\n",
    "**Logistic Regression; </br>\n",
    "Gaussian Discriminant Analysis;</br>\n",
    "Naive Bayes Gaussian;</br>\n",
    "KNN (k = 1 and k = 5; distances: Euclidean and Mahalanobis);</br>\n",
    "Decision tree (gini and entropy).**</br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b9eff4b",
   "metadata": {},
   "source": [
    "### b) For each model created, report mean value and standard deviation of accuracy, recall, precision and F1-score metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6cf4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c5e9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.67400000e+03, 1.27000000e+02, 7.67400000e+03, ...,\n",
       "        0.00000000e+00, 1.00000000e+02, 0.00000000e+00],\n",
       "       [2.00000000e+00, 3.13700000e+04, 2.00000000e+00, ...,\n",
       "        1.00000000e+00, 1.00000000e+02, 0.00000000e+00],\n",
       "       [1.69700000e+03, 3.30000000e+01, 1.70000000e+03, ...,\n",
       "        1.00000000e+00, 5.00000000e+01, 0.00000000e+00],\n",
       "       ...,\n",
       "       [6.09600000e+03, 5.10000000e+01, 6.10200000e+03, ...,\n",
       "        2.00000000e+00, 3.33333333e+01, 1.00000000e+00],\n",
       "       [6.09800000e+03, 3.80000000e+01, 6.10000000e+03, ...,\n",
       "        1.00000000e+00, 1.00000000e+02, 1.00000000e+00],\n",
       "       [6.10300000e+03, 5.50000000e+01, 6.10800000e+03, ...,\n",
       "        1.00000000e+00, 1.11111111e+01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = np.genfromtxt(\"../data/jsvulnerability_balanced.csv\", delimiter = ',')\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd44f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = database[:,:38]\n",
    "y = database[:,38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40abf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2404, 38), (2404,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "530ba418",
   "metadata": {},
   "source": [
    "### a) Cross-validation and evaluation of models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ada61812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6631e8c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_original = []\n",
    "pred_lr_1 = []\n",
    "pred_lr = []\n",
    "pred_adgq = []\n",
    "pred_nbg = []\n",
    "pred_euc_1 = []\n",
    "pred_mah_1 = []\n",
    "pred_euc_5 = []\n",
    "pred_mah_5 = []\n",
    "pred_tree_gini = []\n",
    "pred_tree_etp = []\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle = True) \n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    y_test_original.append(y_test)\n",
    "    \n",
    "    # Logistic Regression: default\n",
    "    clf_lr_1 = LogisticRegression(max_iter=200).fit(X_train_scaled,y_train) # default: penalty = l2, solver = lbfgs\n",
    "    pred_clf_lr_1 = clf_lr_1.predict(X_test_scaled)\n",
    "    pred_lr_1.append(pred_clf_lr_1)\n",
    "    \n",
    "    # Logistic Regression: penalty = 'none', solver='newton-cg'\n",
    "    clf_lr = LogisticRegression(penalty='none', solver = 'newton-cg').fit(X_train_scaled,y_train)\n",
    "    pred_clf_lr = clf_lr.predict(X_test_scaled)\n",
    "    pred_lr.append(pred_clf_lr)\n",
    "    \n",
    "    # Gaussian Discriminant Analysis - Quadratic:                  \n",
    "    clf_adgq = QuadraticDiscriminantAnalysis().fit(X_train_scaled, y_train)\n",
    "    pred_clf_adgq = clf_adgq.predict(X_test_scaled)\n",
    "    pred_adgq.append(pred_clf_adgq)\n",
    "    \n",
    "    # Naive Bayes Gaussian:\n",
    "    clf_nbg = GaussianNB().fit(X_train_scaled, y_train)\n",
    "    pred_clf_nbg = clf_nbg.predict(X_test_scaled)\n",
    "    pred_nbg.append(pred_clf_nbg)\n",
    "    \n",
    "    # KNN => k = 1\n",
    "    neigh_euc_1 = KNeighborsClassifier(n_neighbors=1, metric = 'euclidean').fit(X_train_scaled, y_train)\n",
    "    pred_neigh_euc_1 = neigh_euc_1.predict(X_test_scaled)\n",
    "    pred_euc_1.append(pred_neigh_euc_1)\n",
    "\n",
    "    neigh_mah_1 = KNeighborsClassifier(n_neighbors=1, metric = 'mahalanobis', \n",
    "                                       metric_params={'VI': np.linalg.inv(np.cov(X_train_scaled.T))}).fit(X_train_scaled, y_train)\n",
    "    pred_neigh_mah_1 = neigh_mah_1.predict(X_test_scaled)\n",
    "    pred_mah_1.append(pred_neigh_mah_1)\n",
    "    \n",
    "    # KNN => k = 5\n",
    "    neigh_euc_5 = KNeighborsClassifier(n_neighbors=5, metric = 'euclidean').fit(X_train_scaled, y_train)\n",
    "    pred_neigh_euc_5 = neigh_euc_5.predict(X_test_scaled)\n",
    "    pred_euc_5.append(pred_neigh_euc_5)\n",
    "\n",
    "    neigh_mah_5 = KNeighborsClassifier(n_neighbors=5, metric = 'mahalanobis', \n",
    "                                       metric_params={'VI': np.linalg.inv(np.cov(X_train_scaled.T))}).fit(X_train_scaled, y_train)\n",
    "    pred_neigh_mah_5 = neigh_mah_5.predict(X_test_scaled)\n",
    "    pred_mah_5.append(pred_neigh_mah_5)\n",
    "    \n",
    "    # Decision Tree: criterion = gini (default)\n",
    "    clf_tree_gini = tree.DecisionTreeClassifier(criterion='gini').fit(X_train_scaled, y_train)\n",
    "    pred_clf_tree_gini = clf_tree_gini.predict(X_test_scaled)\n",
    "    pred_tree_gini.append(pred_clf_tree_gini)\n",
    "    \n",
    "    # Decision Tree: criterion = entropy\n",
    "    clf_tree_etp = tree.DecisionTreeClassifier(criterion='entropy').fit(X_train_scaled, y_train)\n",
    "    pred_clf_tree_etp = clf_tree_etp.predict(X_test_scaled)\n",
    "    pred_tree_etp.append(pred_clf_tree_etp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "deb15589",
   "metadata": {},
   "source": [
    "### b) Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778b5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_test, pred):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1_score = []\n",
    "    accuracy = []\n",
    "    for i in range(len(y_test)):\n",
    "        a = classification_report(y_test[i], pred[i], output_dict=True)\n",
    "        precision.append(a['macro avg']['precision'])\n",
    "        recall.append(a['macro avg']['recall'])\n",
    "        f1_score.append(a['macro avg']['f1-score'])\n",
    "        accuracy.append(a['accuracy'])\n",
    "    \n",
    "    results = print(f' Acurácia: {np.mean(accuracy)} +- {np.std(accuracy)} \\n Precisão: {np.mean(precision)} +- {np.std(precision)} \\n Revocação: {np.mean(recall)} +- {np.std(recall)} \\n F1-score: {np.mean(f1_score)} +- {np.std(f1_score)}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ad26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - default:\n",
      " Acurácia: 0.7920055325034577 +- 0.02550414360191054 \n",
      " Precisão: 0.7942683272219808 +- 0.025906136130885427 \n",
      " Revocação: 0.7930790062277875 +- 0.02524614553820512 \n",
      " F1-score: 0.7914037689389367 +- 0.025511736109082098\n",
      "\n",
      "\n",
      "Logistic Regression - penalty L2 and solver = newton-cg:\n",
      " Acurácia: 0.7965923236514523 +- 0.0224722353947443 \n",
      " Precisão: 0.7971873789525485 +- 0.023515192015251905 \n",
      " Revocação: 0.7970952650106613 +- 0.022878566647799636 \n",
      " F1-score: 0.7960591810067392 +- 0.022580766050030118\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression - default:')\n",
    "metrics(y_test_original, pred_lr_1)\n",
    "print('\\n')\n",
    "print('Logistic Regression - penalty L2 and solver = newton-cg:')\n",
    "metrics(y_test_original, pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e49356fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Discriminant Analysis - Quadratic: \n",
      " Acurácia: 0.7304581604426003 +- 0.03001102170252861 \n",
      " Precisão: 0.7747049622025081 +- 0.03366421705779762 \n",
      " Revocação: 0.7298496678375547 +- 0.026278677129690932 \n",
      " F1-score: 0.7183439376749668 +- 0.02932625818655259\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian Discriminant Analysis - Quadratic: ')\n",
    "metrics(y_test_original, pred_adgq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eaec4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes : \n",
      " Acurácia: 0.5990248962655602 +- 0.037772895138225564 \n",
      " Precisão: 0.6653546516094611 +- 0.05188123614442771 \n",
      " Revocação: 0.5993970291511654 +- 0.029263114607328188 \n",
      " F1-score: 0.5548224560597814 +- 0.03880519616665795\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian Naive Bayes : ')\n",
    "metrics(y_test_original, pred_nbg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c140b69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1 and Distance: Euclidean \n",
      " Acurácia: 0.8027991009681881 +- 0.020500033329396174 \n",
      " Precisão: 0.8032342294308062 +- 0.021077327770256813 \n",
      " Revocação: 0.8019848036718231 +- 0.019350852120842046 \n",
      " F1-score: 0.8019114829334469 +- 0.019850727259052996\n",
      "\n",
      "\n",
      "k = 1 and Distance: Mahalanobis \n",
      " Acurácia: 0.7229062932226833 +- 0.06766440390373905 \n",
      " Precisão: 0.7244281029739871 +- 0.06665989460104255 \n",
      " Revocação: 0.7237172744885326 +- 0.0665900213113159 \n",
      " F1-score: 0.7222915982078252 +- 0.0676187882455649\n",
      "\n",
      "\n",
      "k = 5 and Distance: Euclidean \n",
      " Acurácia: 0.8040681189488244 +- 0.025505740830760317 \n",
      " Precisão: 0.8049147605312642 +- 0.02520351308585955 \n",
      " Revocação: 0.8042416207538731 +- 0.02540320468091198 \n",
      " F1-score: 0.8033884047757429 +- 0.025543836464920793\n",
      "\n",
      "\n",
      "k = 5 and Distance: Mahalanobis \n",
      " Acurácia: 0.733366182572614 +- 0.07047669095230319 \n",
      " Precisão: 0.7370528497467875 +- 0.07170026307828199 \n",
      " Revocação: 0.7350667332038594 +- 0.07028069923859348 \n",
      " F1-score: 0.7327350168781636 +- 0.07033666376666577\n"
     ]
    }
   ],
   "source": [
    "# KNN => k = 1 e k = 5\n",
    "print('k = 1 and Distance: Euclidean ')\n",
    "metrics(y_test_original, pred_euc_1)\n",
    "print('\\n')\n",
    "print('k = 1 and Distance: Mahalanobis ')\n",
    "metrics(y_test_original, pred_mah_1)\n",
    "print('\\n')\n",
    "print('k = 5 and Distance: Euclidean ')\n",
    "metrics(y_test_original, pred_euc_5)\n",
    "print('\\n')\n",
    "print('k = 5 and Distance: Mahalanobis ')\n",
    "metrics(y_test_original, pred_mah_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1f7ca28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: criterion = gini: \n",
      " Acurácia: 0.8331621715076072 +- 0.03326392853121862 \n",
      " Precisão: 0.8332716681237688 +- 0.033085740247334045 \n",
      " Revocação: 0.8326057775933879 +- 0.03286953959423914 \n",
      " F1-score: 0.8325023892978545 +- 0.03303974804584576\n",
      "\n",
      "\n",
      "Decision Tree: criterion = entropy: \n",
      " Acurácia: 0.8302489626556018 +- 0.030421659234771872 \n",
      " Precisão: 0.8299453271359288 +- 0.030594045499836575 \n",
      " Revocação: 0.8301366456454226 +- 0.030344412239406145 \n",
      " F1-score: 0.8297229880334713 +- 0.030415730444142464\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree: criterion = gini and entropy\n",
    "print('Decision Tree: criterion = gini: ')\n",
    "metrics(y_test_original, pred_tree_gini)\n",
    "print('\\n')\n",
    "print('Decision Tree: criterion = entropy: ')\n",
    "metrics(y_test_original, pred_tree_etp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc7c82b1",
   "metadata": {},
   "source": [
    "Decision Tree with criterion gini is the model with the best metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
